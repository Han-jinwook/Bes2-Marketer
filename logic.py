"""
Bes2 Marketer - Core Logic Module
YouTube Hunter + AI Copywriter
"""

from typing import Optional
from datetime import datetime, timedelta

from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api._errors import (
    TranscriptsDisabled,
    NoTranscriptFound,
    VideoUnavailable
)
import re
import google.generativeai as genai

from config import config
from database import db


# =============================================
# YouTube Hunter - ì˜ìƒ ê²€ìƒ‰ ë° ìë§‰ ì¶”ì¶œ
# =============================================

class YouTubeHunter:
    """YouTube ì˜ìƒ ê²€ìƒ‰ ë° ìë§‰ ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.youtube = build(
            "youtube", "v3",
            developerKey=config.YOUTUBE_API_KEY
        )
    
    def search_videos(self, keyword: str, max_results: int = 10, published_after_days: int = 30, min_view_count: int = 0, require_email: bool = False) -> tuple[list[dict], int]:
        """
        ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰ (Deep Search ì ìš©)
        - require_email=True ì‹œ ì´ë©”ì¼ ì—†ëŠ” ì˜ìƒì€ ê²°ê³¼ì—ì„œ ì œì™¸
        """
        from database import db
        
        # 1. ë‚ ì§œ ë° ì´ˆê¸°ê°’ ì„¤ì •
        published_after = (datetime.utcnow() - timedelta(days=published_after_days)).isoformat("T") + "Z"
        print(f"Searching for '{keyword}' after {published_after}...")
        
        known_ids = db.get_known_video_ids()
        collected_items = []
        next_page_token = None
        total_results_approx = 0
        
        # 2. 1ì°¨ ê²€ìƒ‰ (ìµœëŒ€ 10í˜ì´ì§€ = 500ê°œ í›„ë³´êµ° íƒìƒ‰)
        for page_num in range(10):
            try:
                search_response = self.youtube.search().list(
                    q=keyword, part="id,snippet", maxResults=50,
                    order="date", publishedAfter=published_after, type="video", pageToken=next_page_token
                ).execute()
                
                if page_num == 0:
                    total_results_approx = search_response.get("pageInfo", {}).get("totalResults", 0)

                items = search_response.get("items", [])
                if not items: break
                
                # í•„í„°ë§ í—¬í¼
                import re
                def has_korean(text): return bool(re.search(r'[ê°€-í£]', text))
                required_terms = keyword.split()
                
                for item in items:
                    if len(collected_items) >= max_results: break
                    vid = item["id"]["videoId"]
                    snippet = item["snippet"]
                    
                    # (1) DB ì¤‘ë³µ ì²´í¬
                    if vid in known_ids: continue
                    # (2) í•œêµ­ì–´ ì²´í¬
                    if not has_korean(snippet["title"]): continue
                    # (3) í‚¤ì›Œë“œ ë§¤ì¹­
                    search_context = (snippet["title"] + " " + snippet["description"]).lower()
                    if not all(term.lower() in search_context for term in required_terms): continue
                    
                    collected_items.append({
                        "video_id": vid,
                        "title": snippet["title"],
                        "description": snippet["description"], # ì˜ìƒ ì„¤ëª… (ì´ë©”ì¼ ì¶”ì¶œìš© 1ìˆœìœ„)
                        "thumbnail_url": snippet["thumbnails"]["high"]["url"],
                        "published_at": snippet["publishedAt"],
                        "channel_id": snippet["channelId"],
                        "channel_name": snippet["channelTitle"],
                        "video_url": f"https://www.youtube.com/watch?v={vid}"
                    })
                
                if len(collected_items) >= max_results: break
                
                next_page_token = search_response.get("nextPageToken")
                if not next_page_token: break
                
                # [Safety] ëœë¤ ë”œë ˆì´
                import time, random
                time.sleep(random.uniform(1, 3))
                
                print(f"Page {page_num+1} done. Collected candidates: {len(collected_items)}")

            except Exception as e:
                print(f"Search API Error: {e}")
                break
        
        # 3. 2ì°¨ ìƒì„¸ ì¡°íšŒ (í†µê³„ í™•ì¸ ë° ì´ë©”ì¼ ì‚¬ëƒ¥)
        final_items = []
        if collected_items:
            try:
                # 50ê°œì”© ëŠì–´ì„œ ì²˜ë¦¬ (Detail API Quota ì ˆì•½)
                filtered_candidates = collected_items[:max_results] # ì¼ë‹¨ ìµœëŒ€ì¹˜ë§Œí¼ ìë¦„
                chunk_size = 50
                
                for i in range(0, len(filtered_candidates), chunk_size):
                    chunk = filtered_candidates[i:i + chunk_size]
                    video_ids = [v["video_id"] for v in chunk]
                    
                    # (1) ì˜ìƒ í†µê³„ (ì¡°íšŒìˆ˜)
                    stats_resp = self.youtube.videos().list(part="statistics", id=",".join(video_ids)).execute()
                    stats_map = {item["id"]: item["statistics"] for item in stats_resp.get("items", [])}
                    
                    # (2) ì±„ë„ ì •ë³´ (ì„¤ëª…ê¸€ì—ì„œ ì´ë©”ì¼ ì°¾ê¸°ìš© 2ìˆœìœ„)
                    channel_ids = list({v["channel_id"] for v in chunk})
                    channel_map = {}
                    for k in range(0, len(channel_ids), 50):
                        c_chunk = channel_ids[k:k+50]
                        chan_resp = self.youtube.channels().list(part="statistics,snippet", id=",".join(c_chunk)).execute()
                        for c_item in chan_resp.get("items", []):
                            channel_map[c_item["id"]] = {
                                "subscriber_count": int(c_item["statistics"].get("subscriberCount", 0)),
                                "description": c_item["snippet"].get("description", "")
                            }
                    
                    for v in chunk:
                        vid = v["video_id"]
                        cid = v["channel_id"]
                        
                        # ì¡°íšŒìˆ˜ í•„í„°ë§
                        view_count = 0
                        if vid in stats_map:
                            view_count = int(stats_map[vid].get("viewCount", 0))
                            v["view_count"] = view_count
                        
                        if min_view_count > 0 and view_count < min_view_count:
                            continue
                            
                        # ì´ë©”ì¼ ì¶”ì¶œ (3ë‹¨ê³„ ì „ëµ)
                        chan_info = channel_map.get(cid, {})
                        
                        # 1. ì˜ìƒ ì„¤ëª…
                        email = self._extract_email_from_text(v["description"])
                        
                        # 2. ì±„ë„ ì„¤ëª…
                        if not email:
                            email = self._extract_email_from_text(chan_info.get("description", ""))
                        
                        # [NEW] 3. DB ì¡°íšŒ (ê³¼ê±° ìˆ˜ì§‘ ê¸°ë¡)
                        if not email:
                            existing_lead = db.get_lead_by_channel_id(cid)
                            if existing_lead and existing_lead.get("email"):
                                email = existing_lead["email"]

                            
                        # ì´ë©”ì¼ í•„ìˆ˜ í•„í„°ë§
                        if require_email and not email:
                            continue
                            
                        v["channel_info"] = {
                            "subscriber_count": chan_info.get("subscriber_count", 0),
                            "email": email
                        }
                        final_items.append(v)
            
            except Exception as e:
                print(f"Detail API Error: {e}")
                # ì—ëŸ¬ ë‚˜ë”ë¼ë„ ìˆ˜ì§‘í•œ ê±´ ë°˜í™˜
                return collected_items[:max_results], 0

        # í•„í„°ë§ í›„ ìµœì¢… ê²°ê³¼ ë¦¬í„´
        return final_items, total_results_approx
    
    def _extract_email_from_text(self, text: str) -> Optional[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì´ë©”ì¼ íŒ¨í„´ ì¶”ì¶œ"""
        if not text:
            return None
        # ì´ë©”ì¼ ì •ê·œì‹ (ê°„ë‹¨ ë²„ì „)
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        match = re.search(email_pattern, text)
        return match.group(0) if match else None

    def _get_channel_details(self, channel_id: str) -> dict:
        """ì±„ë„ ìƒì„¸ ì •ë³´(ì„¤ëª…, êµ¬ë…ì ìˆ˜) ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.youtube.channels().list(
                part="snippet,statistics",
                id=channel_id
            ).execute()
            
            if response["items"]:
                item = response["items"][0]
                return {
                    "description": item["snippet"]["description"],
                    "subscriber_count": int(item["statistics"]["subscriberCount"])
                }
        except:
            pass
        return {"description": "", "subscriber_count": 0}
    
    def _get_video_details(self, video_id: str) -> dict:
        """ì˜ìƒ ìƒì„¸ í†µê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.youtube.videos().list(
                part="statistics",
                id=video_id
            ).execute()
            
            if response["items"]:
                stats = response["items"][0]["statistics"]
                return {
                    "view_count": int(stats.get("viewCount", 0)),
                    "like_count": int(stats.get("likeCount", 0)),
                    "comment_count": int(stats.get("commentCount", 0))
                }
        except Exception as e:
            print(f"Error getting video details: {e}")
        
        return {}
    
    def get_channel_info(self, channel_id: str) -> Optional[dict]:
        """ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.youtube.channels().list(
                part="snippet,statistics",
                id=channel_id
            ).execute()
            
            if response["items"]:
                item = response["items"][0]
                snippet = item["snippet"]
                stats = item["statistics"]
                
                return {
                    "channel_id": channel_id,
                    "channel_name": snippet["title"],
                    "description": snippet["description"],
                    "thumbnail_url": snippet["thumbnails"]["high"]["url"],
                    "channel_url": f"https://www.youtube.com/channel/{channel_id}",
                    "subscriber_count": int(stats.get("subscriberCount", 0)),
                    "video_count": int(stats.get("videoCount", 0)),
                    "view_count": int(stats.get("viewCount", 0)),
                    # ì´ë©”ì¼ ì¶”ì¶œ ì‹œë„ (ì„¤ëª…ì—ì„œ)
                    "email": self._extract_email_from_text(snippet["description"])
                }
        except Exception as e:
            print(f"Error getting channel info: {e}")
        
        return None
    
    def get_transcript(
        self,
        video_id: str,
        languages: list[str] = ["ko", "en"]
    ) -> Optional[str]:
        """
        ì˜ìƒ ìë§‰ ì¶”ì¶œ (ìµœëŒ€í•œ ê°•ë ¥í•˜ê²Œ - Raw ëª¨ë“œ)
        """
        try:
            print(f"[Transcript] Fetching for {video_id}...")
            
            # 1. ìë§‰ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            # (cookies.txtê°€ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ì—¬ IP ì°¨ë‹¨/ì—°ë ¹ ì œí•œ ìš°íšŒ)
            import os
            cookies_path = os.path.join(os.path.dirname(__file__), 'cookies.txt')
            
            if os.path.exists(cookies_path):
                print(f"   ğŸª Using cookies from {cookies_path}")
                transcript_list = YouTubeTranscriptApi.list_transcripts(video_id, cookies=cookies_path)
            else:
                transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)

            # 2. ìš°ì„ ì ìœ¼ë¡œ ìˆ˜ë™ ìƒì„± ìë§‰ ì°¾ê¸°
            try:
                transcript = transcript_list.find_manually_created_transcript(languages)
                print("   âœ… Found Manual Transcript")
            except NoTranscriptFound:
                # ì—†ìœ¼ë©´ ìë™ ìƒì„± ìë§‰ ì°¾ê¸°
                try:
                    print("   âš ï¸ No Manual, trying Auto-generated...")
                    transcript = transcript_list.find_generated_transcript(languages)
                    print("   âœ… Found Auto-generated Transcript")
                except NoTranscriptFound:
                    print("   âŒ No transcript found in requested languages.")
                    return None
            
            # 3. ìë§‰ ê°€ì ¸ì˜¤ê¸°
            script = transcript.fetch()
            
            # í…ìŠ¤íŠ¸ë§Œ í•©ì¹˜ê¸°
            full_text = " ".join([entry['text'] for entry in script])
            return full_text
            
        except TranscriptsDisabled:
            print(f"   âŒ Transcripts are disabled for video {video_id}")
            return None
        except Exception as e:
            print(f"   âŒ Error fetching transcript: {e}")
            return None


# =============================================
# AI Copywriter - Gemini ê¸°ë°˜ ë¶„ì„ ë° ì‘ì„±
# =============================================

class AICopywriter:
    """Gemini AIë¥¼ ì´ìš©í•œ ì˜ìƒ ë¶„ì„ ë° ë§ˆì¼€íŒ… ì¹´í”¼ ì‘ì„±"""
    
    def __init__(self):
        genai.configure(api_key=config.GEMINI_API_KEY)
        # ìµœì‹  ëª¨ë¸ ì‚¬ìš© (Gemini 1.5 Flash - ë¹ ë¥´ê³  ì €ë ´í•¨)
        self.model = genai.GenerativeModel('gemini-1.5-flash')

    def analyze_video(self, video_data: dict, transcript: str) -> dict:
        """ì˜ìƒ ë‚´ìš© ë¶„ì„ ë° íŠ¸ë Œë“œ íŒŒì•…"""
        prompt = f'''
        ë‹¤ìŒì€ ìœ íŠœë¸Œ ì˜ìƒì˜ ì •ë³´ì™€ ìë§‰ì…ë‹ˆë‹¤.
        
        [ì œëª©]: {video_data.get('title')}
        [ì±„ë„]: {video_data.get('channel_name')}
        [ìë§‰ ë‚´ìš©]:
        {transcript[:10000]} (ì¤‘ëµ...)
        
        ì´ ì˜ìƒì„ ë¶„ì„í•´ì„œ ë‹¤ìŒ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì¤˜:
        1. summary: ì˜ìƒ ë‚´ìš© 3ì¤„ ìš”ì•½
        2. pain_points: ì‹œì²­ìê°€ ê²ªê³  ìˆëŠ” ë¬¸ì œì (Pain Point) 3ê°€ì§€ëŠ”?
        3. target_audience: ì´ ì˜ìƒì˜ í•µì‹¬ íƒ€ê²Ÿ ì‹œì²­ìì¸µ
        4. relevance_score: ì´ ì˜ìƒê³¼ 'ì‚¬ì§„ ì •ë¦¬/ë°±ì—… ì†”ë£¨ì…˜'ì˜ ê´€ë ¨ ì ìˆ˜ (0~100ì )
        '''
        
        try:
            response = self.model.generate_content(prompt)
            return self._parse_json_response(response.text)
        except Exception as e:
            print(f"AI Analysis Error: {e}")
            return {"summary": "ë¶„ì„ ì‹¤íŒ¨", "relevance_score": 0}

    def generate_email_draft(self, video_data: dict, analysis: dict) -> str:
        """ì½œë“œ ë©”ì¼ ì´ˆì•ˆ ì‘ì„±"""
        prompt = f'''
        ë‹¹ì‹ ì€ "êµ¬ê¸€ í¬í†  ìš©ëŸ‰ ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ëŠ” AI ì‚¬ì§„ ì •ë¦¬ ì•±(Bes2Gallery)"ì˜ ë§ˆì¼€í„°ì…ë‹ˆë‹¤.
        ìœ íŠœë²„ '{video_data.get('channel_name')}'ë‹˜ì—ê²Œ ì œíœ´ ì œì•ˆ ë©”ì¼ì„ ì¨ì£¼ì„¸ìš”.
        
        [ì˜ìƒ ì •ë³´]
        - ì œëª©: {video_data.get('title')}
        - ë¶„ì„: {analysis.get('summary')}
        - Pain Point: {analysis.get('pain_points')}
        
        [ë©”ì¼ ì‘ì„± ê°€ì´ë“œ]
        1. ì œëª©ì€ í´ë¦­ë¥ ì´ ë†’ê²Œ, ì˜ìƒ ë‚´ìš©ì„ ì–¸ê¸‰í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ.
        2. ì„œë¡ ì—ì„œ í•´ë‹¹ ì˜ìƒì„ ì˜ ë´¤ë‹¤ëŠ” êµ¬ì²´ì ì¸ ì¹­ì°¬ìœ¼ë¡œ ì‹œì‘ (ì§„ì •ì„±).
        3. ë³¸ë¡ ì—ì„œ ì‹œì²­ìë“¤ì´ ê²ªëŠ” 'ì‚¬ì§„ ìš©ëŸ‰ ë¶€ì¡±' ë¬¸ì œë¥¼ ì§šì–´ì£¼ê³ , ìš°ë¦¬ ì•±ì´ í•´ê²°ì±…ì„ì„ ì œì‹œ.
        4. ì œì•ˆ: ìœ ë£Œ ê´‘ê³ ê°€ ì•„ë‹ˆë¼ ê°€ë³ê²Œ ì†Œê°œí•´ì£¼ì‹œë©´ êµ¬ë…ì ì´ë²¤íŠ¸ë¥¼ ì§€ì›í•˜ê² ë‹¤ëŠ” í†¤ìœ¼ë¡œ.
        5. ì •ì¤‘í•˜ê³  ê¹”ë”í•œ í•œêµ­ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ ë©”ì¼ í˜•ì‹.
        '''
        
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"ì‘ì„± ì‹¤íŒ¨: {e}"

    def _parse_json_response(self, text: str) -> dict:
        """Gemini ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ (ê°„ë‹¨ íŒŒì‹±)"""
        import json
        text = text.replace("```json", "").replace("```", "").strip()
        try:
            return json.loads(text)
        except:
            return {"summary": text[:200], "relevance_score": 50}

# =============================================
# ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì™¸ë¶€ ì‚¬ìš©ìš©)
# =============================================
hunter = YouTubeHunter()
copywriter = AICopywriter()
